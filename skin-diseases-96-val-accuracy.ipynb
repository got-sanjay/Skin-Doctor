{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6695743,"sourceType":"datasetVersion","datasetId":3860205}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T04:55:44.682450Z","iopub.execute_input":"2025-05-21T04:55:44.682690Z","iopub.status.idle":"2025-05-21T04:55:44.691561Z","shell.execute_reply.started":"2025-05-21T04:55:44.682663Z","shell.execute_reply":"2025-05-21T04:55:44.690885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs('dataset')\nimport shutil\nsrc=\"/kaggle/input/skin-disease-dataset/skin-disease-datasaet\"\ndes=\"/kaggle/working/dataset\"\n#shutil.copytree(src=\"/kaggle/input/skin-diseases-image-dataset\",dst=\"/kaggle/working/sim\")\nif os.path.exists(des):\n        shutil.rmtree(des)\n        shutil.copytree(src, des)","metadata":{"execution":{"iopub.status.busy":"2025-05-21T04:55:58.217439Z","iopub.execute_input":"2025-05-21T04:55:58.217700Z","iopub.status.idle":"2025-05-21T04:56:07.470612Z","shell.execute_reply.started":"2025-05-21T04:55:58.217680Z","shell.execute_reply":"2025-05-21T04:56:07.469826Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(\"/kaggle/working/dataset\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# loc=\"/kaggle/working/dataset/IMG_CLASSES\"\n# !pip install split_folders\n# import splitfolders\n# import os\n# os.makedirs('output')\n# os.makedirs('output/train')\n# os.makedirs('output/val')\n# os.makedirs('output/test')\n# splitfolders.ratio(loc,output = \"output\",seed = 42,ratio = (0.80,.1,.1))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport seaborn as sns\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"float32\")","metadata":{"execution":{"iopub.status.busy":"2025-05-21T04:56:36.713991Z","iopub.execute_input":"2025-05-21T04:56:36.714934Z","iopub.status.idle":"2025-05-21T04:56:36.718746Z","shell.execute_reply.started":"2025-05-21T04:56:36.714909Z","shell.execute_reply":"2025-05-21T04:56:36.717924Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from tensorflow.keras.preprocessing import image_dataset_from_directory\n# train_dir=\"./output/train\"\n# test_dir=\"./output/test\"\n# val_dir=\"./output/val\"\n# train_data=image_dataset_from_directory(train_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=True,seed=42)\n# test_data=image_dataset_from_directory(test_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=False,seed=42)\n# val_data=image_dataset_from_directory(val_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=False,seed=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ### INCEPTION V3\n# from tensorflow.keras.preprocessing import image_dataset_from_directory\n# train_dir=\"./output/train\"\n# test_dir=\"./output/test\"\n# val_dir=\"./output/val\"\n\n# train_data=image_dataset_from_directory(train_dir,batch_size=32,image_size=(299,299),label_mode='categorical',shuffle=True,seed=42)\n# test_data=image_dataset_from_directory(test_dir,batch_size=32,image_size=(299,299),label_mode='categorical',shuffle=False,seed=42)\n# val_data=image_dataset_from_directory(val_dir,batch_size=32,image_size=(299,299),label_mode='categorical',shuffle=False,seed=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_dir=\"./dataset/train_set\"\ntest_dir=\"./dataset/test_set\"\nval_dir=\"./dataset/test_set\"\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=10,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='sparse',      \n    subset='training',\n    shuffle=True\n)\n\nval_generator = train_datagen.flow_from_directory(\n    val_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='sparse',     \n    subset='validation',\n    shuffle=False\n)\n\ntest_generator = train_datagen.flow_from_directory(\n    test_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='sparse',      \n    shuffle=False\n)\n# train_data=image_dataset_from_directory(train_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=True,seed=42)\n# test_data=image_dataset_from_directory(test_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=False,seed=42)\n# val_data=image_dataset_from_directory(val_dir,batch_size=32,image_size=(224,224),label_mode='categorical',shuffle=False,seed=42)","metadata":{"execution":{"iopub.status.busy":"2025-05-21T04:56:41.263022Z","iopub.execute_input":"2025-05-21T04:56:41.263631Z","iopub.status.idle":"2025-05-21T04:56:41.322573Z","shell.execute_reply.started":"2025-05-21T04:56:41.263609Z","shell.execute_reply":"2025-05-21T04:56:41.321880Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, labels = next(train_generator)\nprint(images.shape)  # (32, 224, 224, 3)\nprint(labels.shape) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T04:56:51.150289Z","iopub.execute_input":"2025-05-21T04:56:51.150827Z","iopub.status.idle":"2025-05-21T04:56:51.524818Z","shell.execute_reply.started":"2025-05-21T04:56:51.150806Z","shell.execute_reply":"2025-05-21T04:56:51.524180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names=train_generator.class_indices\nclass_count=train_generator.num_classes\nprint(class_count)\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2025-05-21T04:57:04.080081Z","iopub.execute_input":"2025-05-21T04:57:04.080865Z","iopub.status.idle":"2025-05-21T04:57:04.085177Z","shell.execute_reply.started":"2025-05-21T04:57:04.080837Z","shell.execute_reply":"2025-05-21T04:57:04.084234Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras_tuner as kt\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam, SGD, Adamax\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.losses import categorical_crossentropy, sparse_categorical_crossentropy, KLDivergence\n\n\ndef build_model(hp):\n    # InceptionV3\n    base_model = InceptionV3(include_top=False, \n                             weights=\"imagenet\", \n                             input_shape=(224, 224, 3), \n                             pooling=hp.Choice(\"pooling\", [\"avg\", \"max\"])\n                            )\n        \n    \n    base_model.trainable = False  # Or fine-tune later\n    \n    x = base_model.output\n    x = BatchNormalization()(x)\n\n    # Tune regularizers ON/OFF\n    use_kernel_reg = hp.Boolean(\"use_kernel_regularizer\")\n    use_bias_reg = hp.Boolean(\"use_bias_regularizer\")\n    use_activity_reg = hp.Boolean(\"use_activity_regularizer\")\n\n    # Define regularizer values (only used if enabled)\n    kernel_reg = regularizers.l2(hp.Float(\"kernel_l2\", 1e-4, 1e-2, sampling=\"log\")) if use_kernel_reg and use_activity_reg else None\n    bias_reg = regularizers.l1(hp.Float(\"bias_l1\", 1e-4, 1e-2, sampling=\"log\")) if use_bias_reg else None\n    activity_reg = regularizers.l1(hp.Float(\"activity_l1\", 1e-4, 1e-2, sampling=\"log\")) if use_kernel_reg and use_activity_reg else None\n\n    # Tune number of dense layers\n    for i in range(hp.Int(\"num_dense_layers\", 1, 3)):\n        units = hp.Int(f\"dense_units_{i}\", min_value=64, max_value=512, step=32)\n        l2_val = hp.Float(f\"l2_{i}\", 1e-3, 1e-1, sampling=\"log\")\n        l1_val = hp.Float(f\"l1_{i}\", 1e-3, 1e-1, sampling=\"log\")\n        x = Dense(\n            units,\n            activation='relu',\n            kernel_regularizer=kernel_reg,\n            activity_regularizer=activity_reg\n        )(x)\n        if hp.Boolean(f\"batchnorm_{i}\"):\n            x = BatchNormalization()(x)\n        x = Dropout(hp.Float(f\"dropout_{i}\", 0.2, 0.5, step=0.1))(x)\n\n\n    output = Dense(class_count, activation=\"softmax\")(x)\n\n    model = Model(inputs=base_model.input, outputs=output)\n\n    # Optimizer and learning rate\n    optimizer_name = hp.Choice(\"optimizer\", [\"adam\", \"adamax\",\"sgd\"])\n    lr = hp.Float(\"learning_rate\", 1e-3, 1e-1, sampling=\"log\")\n\n    if optimizer_name == \"adam\":\n        optimizer = Adam(learning_rate=lr)\n    elif optimizer_name == \"sgd\":\n        optimizer = SGD(learning_rate=lr)\n    else:\n        optimizer = Adamax(learning_rate=lr)\n        \n    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T04:57:15.877296Z","iopub.execute_input":"2025-05-21T04:57:15.877573Z","iopub.status.idle":"2025-05-21T04:57:16.249516Z","shell.execute_reply.started":"2025-05-21T04:57:15.877554Z","shell.execute_reply":"2025-05-21T04:57:16.248747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n\nearly_stop = [\n    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n    ModelCheckpoint(filepath='best_model.h5',monitor='val_accuracy',save_best_only=True,save_weights_only=False,verbose=1),\n    ReduceLROnPlateau(monitor='val_loss',factor=0.3,patience=3,min_lr=1e-6,verbose=1)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T04:57:22.438808Z","iopub.execute_input":"2025-05-21T04:57:22.439341Z","iopub.status.idle":"2025-05-21T04:57:22.446443Z","shell.execute_reply.started":"2025-05-21T04:57:22.439317Z","shell.execute_reply":"2025-05-21T04:57:22.445845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tuner = kt.RandomSearch(\n    build_model,\n    objective=\"val_accuracy\",\n    max_trials=100,  # Increase for deeper tuning\n    executions_per_trial=1,\n    directory=\"kt_regularized\",\n    project_name=\"skin_disease_full_tune\"\n)\n\ntuner.search(train_generator , validation_data=test_generator , epochs=20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T06:53:28.550489Z","iopub.execute_input":"2025-05-21T06:53:28.551181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_hps = tuner.get_best_hyperparameters(1)[0]\nfor param in best_hps.values:\n    print(f\"{param}: {best_hps.get(param)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T06:53:46.387025Z","iopub.execute_input":"2025-05-21T06:53:46.387771Z","iopub.status.idle":"2025-05-21T06:53:46.392282Z","shell.execute_reply.started":"2025-05-21T06:53:46.387741Z","shell.execute_reply":"2025-05-21T06:53:46.391601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tuner.hypermodel.build(best_hps)\n\nhistory = model.fit(test_generator, validation_data=test_generator, epochs=30, callbacks=[early_stop])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T06:59:09.861446Z","iopub.execute_input":"2025-05-21T06:59:09.862031Z","iopub.status.idle":"2025-05-21T07:02:18.206656Z","shell.execute_reply.started":"2025-05-21T06:59:09.862010Z","shell.execute_reply":"2025-05-21T07:02:18.206102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## efficient_net_b2\n# from tensorflow.keras.layers import Dense,Activation,Dropout,Conv2D,MaxPooling2D,BatchNormalization,Flatten\n# from tensorflow.keras import regularizers\n# from tensorflow.keras.models import Model, load_model, Sequential\n# from tensorflow.keras.callbacks import EarlyStopping\n# model_name='EfficientNetB2'\n# base_model=tf.keras.applications.EfficientNetB2(include_top=False, weights=\"imagenet\",input_shape=(224,224,3), pooling='max') \n# x=base_model.output\n# #x=layers.GlobalAvgPool2D(name = \"pooling_layer\")(x)\n# x=tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n# x=Dense(256, kernel_regularizer = regularizers.l2(l2=0.016),activity_regularizer=regularizers.l1(0.006),\n#                 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n# x=Dense(128, kernel_regularizer = regularizers.l2(0.016),activity_regularizer=regularizers.l1(0.006),\n#                 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n# x=Dropout(rate=.45, seed=42)(x)        \n# output=Dense(class_count, activation='softmax')(x)\n# model=Model(inputs=base_model.input, outputs=output)\n# model.compile(tf.keras.optimizers.SGD(.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n# early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.applications import ResNet101V2\n# from tensorflow.keras import regularizers\n# from tensorflow.keras.callbacks import EarlyStopping\n\n# # Load the base ResNet101V2 model with ImageNet weights\n# base_model = ResNet101V2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3), pooling='max')\n\n# # Add additional layers on top of the base model\n# x = base_model.output\n# x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n# x = Dense(256, kernel_regularizer=regularizers.l2(l=0.016), \n#           activity_regularizer=regularizers.l1(0.006), \n#           bias_regularizer=regularizers.l1(0.006), activation='relu')(x)\n# x = Dense(128, kernel_regularizer=regularizers.l2(l=0.016), \n#           activity_regularizer=regularizers.l1(0.006), \n#           bias_regularizer=regularizers.l1(0.006), activation='relu')(x)\n# x = Dropout(rate=0.45, seed=42)(x)\n# output = Dense(class_count, activation='softmax')(x)\n\n# # Define the complete model\n# model = Model(inputs=base_model.input, outputs=output)\n\n# # Compile the model with optimizer, loss function, and metrics\n# model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001),\n#               loss='categorical_crossentropy',\n#               metrics=['accuracy'])\n\n# # Define early stopping criteria\n# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# # Assuming you have your training and validation data defined as train_data, train_labels, val_data, val_labels\n# # Example:\n# # train_data, train_labels = ...\n# # val_data, val_labels = ...\n\n# # Train the model with early stopping\n# history = model.fit(train_data,\n#                     epochs=100,  # Example number of epochs\n#                     validation_data=val_data,\n#                     callbacks=[early_stopping])\n\n# # Optionally, you can save the trained model\n# model.save('my_resnet_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ### MOBILENET V3\n# from tensorflow.keras.layers import Dense,Activation,Dropout,Conv2D,MaxPooling2D,BatchNormalization,Flatten\n# from tensorflow.keras import regularizers\n# from tensorflow.keras.models import Model, load_model, Sequential\n\n# model_name='MobileNetV3'\n# base_model = tf.keras.applications.MobileNetV3Large(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3), pooling='max')\n\n# x=base_model.output\n# #x=layers.GlobalAvgPool2D(name = \"pooling_layer\")(x)\n# x=tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n# x=Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n#                 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n# x=Dense(128, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n#                 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n# x=Dropout(rate=.45, seed=42)(x)        \n# output=Dense(class_count, activation='softmax')(x)\n# model=Model(inputs=base_model.input, outputs=output)\n# model.compile(tf.keras.optimizers.Adamax(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ### Inception net v3 on 10 classes\n\n# from tensorflow.keras.layers import Dense,Activation,Dropout,Conv2D,MaxPooling2D,BatchNormalization,Flatten\n# from tensorflow.keras import regularizers\n# from tensorflow.keras.models import Model, load_model, Sequential\n# from tensorflow.keras.callbacks import EarlyStopping\n\n# model_name='InceptionV3'\n# base_model = tf.keras.applications.InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3), pooling='max')\n\n# x=base_model.output\n# #x=layers.GlobalAvgPool2D(name = \"pooling_layer\")(x)\n# x=tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n# x=Dense(256, kernel_regularizer = regularizers.l2(0.016),activity_regularizer=regularizers.l1(0.006),\n#                 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n# x=Dense(128, kernel_regularizer = regularizers.l2(0.016),activity_regularizer=regularizers.l1(0.006),\n#                 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n# x=Dropout(rate=.45, seed=42)(x)\n# output=Dense(class_count, activation='softmax')(x)\n# model=Model(inputs=base_model.input, outputs=output)\n# model.compile(tf.keras.optimizers.Adamax(.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n# early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:02:34.574954Z","iopub.execute_input":"2025-05-21T07:02:34.575796Z","iopub.status.idle":"2025-05-21T07:02:34.818621Z","shell.execute_reply.started":"2025-05-21T07:02:34.575762Z","shell.execute_reply":"2025-05-21T07:02:34.817884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # history=model.fit(train_data,epochs = 22,\n# #                      validation_data = val_data)\n# history = model.fit(train_data, epochs=23,\n#                     validation_data=val_data,\n                    \n#                     callbacks=early_stop)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:03:02.195772Z","iopub.execute_input":"2025-05-21T07:03:02.196017Z","iopub.status.idle":"2025-05-21T07:03:02.199554Z","shell.execute_reply.started":"2025-05-21T07:03:02.196001Z","shell.execute_reply":"2025-05-21T07:03:02.198821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_generator)\nprint('test Accuracy:', test_acc)\nprint('test loss:', test_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:03:43.595036Z","iopub.execute_input":"2025-05-21T07:03:43.595337Z","iopub.status.idle":"2025-05-21T07:03:46.681197Z","shell.execute_reply.started":"2025-05-21T07:03:43.595320Z","shell.execute_reply":"2025-05-21T07:03:46.680433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_probs = model.predict(test_generator)\npred_classes = pred_probs.argmax(axis =1)\ny_labels = test_generator.labels\nclass_names = list(test_generator.class_indices.keys())\n# for image,label in test_generator.unbatch():\n#     y_labels.append(label.numpy().argmax())\n\nfrom sklearn.metrics import classification_report\n\nprint(\"Classification Report:\\n\")\nprint(classification_report(y_labels, pred_classes, target_names=class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:08:15.381859Z","iopub.execute_input":"2025-05-21T07:08:15.382191Z","iopub.status.idle":"2025-05-21T07:08:18.478587Z","shell.execute_reply.started":"2025-05-21T07:08:15.382170Z","shell.execute_reply":"2025-05-21T07:08:18.477796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mping\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n    cm = confusion_matrix(y_true, y_pred)\n    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n    n_classes = cm.shape[0] # find the number of classes we're dealing with\n\n  # Plot the figure and make it pretty\n    fig, ax = plt.subplots(figsize=figsize)\n    cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n    fig.colorbar(cax)\n\n  # Are there a list of classes?\n    if classes:\n        labels = classes\n    else:\n        labels = np.arange(cm.shape[0])\n    ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes), # create enough axis slots for each class\n         yticks=np.arange(n_classes), \n         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n         yticklabels=labels)\n  \n  # Make x-axis labels appear on bottom\n    ax.xaxis.set_label_position(\"bottom\")\n    ax.xaxis.tick_bottom()\n\n  ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n    plt.xticks(rotation=70, fontsize=text_size)\n    plt.yticks(fontsize=text_size)\n    threshold = (cm.max() + cm.min()) / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if norm:\n            plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > threshold else \"black\",\n            size=text_size)\n        else:\n            plt.text(j, i, f\"{cm[i, j]}\",\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > threshold else \"black\",\n            size=text_size)\n\n  # Save the figure to the current working directory\n    if savefig:\n        fig.savefig(\"confusion_matrix.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:08:30.597330Z","iopub.execute_input":"2025-05-21T07:08:30.597881Z","iopub.status.idle":"2025-05-21T07:08:30.605940Z","shell.execute_reply.started":"2025-05-21T07:08:30.597859Z","shell.execute_reply":"2025-05-21T07:08:30.605249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"make_confusion_matrix(y_labels,pred_classes,classes = class_names,figsize = (20,20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:08:34.506878Z","iopub.execute_input":"2025-05-21T07:08:34.507436Z","iopub.status.idle":"2025-05-21T07:08:35.183670Z","shell.execute_reply.started":"2025-05-21T07:08:34.507415Z","shell.execute_reply":"2025-05-21T07:08:35.182938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc=history.history[\"accuracy\"]\nloss=history.history[\"loss\"]\nval_acc=history.history[\"val_accuracy\"]\nval_loss=history.history[\"val_loss\"]\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:08:39.681808Z","iopub.execute_input":"2025-05-21T07:08:39.682115Z","iopub.status.idle":"2025-05-21T07:08:39.810258Z","shell.execute_reply.started":"2025-05-21T07:08:39.682090Z","shell.execute_reply":"2025-05-21T07:08:39.809462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:08:42.416968Z","iopub.execute_input":"2025-05-21T07:08:42.417288Z","iopub.status.idle":"2025-05-21T07:08:42.546448Z","shell.execute_reply.started":"2025-05-21T07:08:42.417268Z","shell.execute_reply":"2025-05-21T07:08:42.545780Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## rock-curve","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\n# Predict probabilities for each class on validation data\nval_probs = model.predict(test_generator)\n# Extract true labels\ntrue_labels = np.concatenate([y for x, y in test_generator], axis=0)\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(class_count):\n    fpr[i], tpr[i], _ = roc_curve(true_labels[:, i], val_probs[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(10, 8))\nfor i in range(class_count):\n    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for class %s' % (roc_auc[i], class_names[i]))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:09:12.503016Z","iopub.execute_input":"2025-05-21T07:09:12.503878Z","iopub.status.idle":"2025-05-21T07:14:54.969186Z","shell.execute_reply.started":"2025-05-21T07:09:12.503854Z","shell.execute_reply":"2025-05-21T07:14:54.968072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\nimport tensorflow_hub as hub\n\ndef predict_skin_disease(image_path, model):\n    class_names = class_names\n    Images= []\n    \n    try:\n        img = cv2.imread(str(image_path))\n        Images.append(cv2.resize(img, (224, 224)))\n        image = np.array(Images)\n\n    except Exception as e:\n        return f\"Error processing image: {e}\"\n\n    try:\n        pred = model.predict(image)\n        predicted_class_index = np.argmax(pred)\n        predicted_class_name = class_names[predicted_class_index]\n        return predicted_class_name\n    except Exception as e:\n        return f\"Error during prediction: {e}\"\n\n\nmodel = tf.keras.models.load_model('')\nresult = predict_skin_disease(\"\", model)\nprint(result)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.save(\"IncepV3-8-Class.h5\")\nmodel.save_weights(\"IncepV3-8-Class.weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:17:33.181615Z","iopub.execute_input":"2025-05-21T07:17:33.182350Z","iopub.status.idle":"2025-05-21T07:17:33.864633Z","shell.execute_reply.started":"2025-05-21T07:17:33.182328Z","shell.execute_reply":"2025-05-21T07:17:33.864052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom IPython.display import FileLink\n# FileLink('IncepV3-8-Class.h5')\nFileLink('IncepV3-8-Class.weights.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T07:18:00.194785Z","iopub.execute_input":"2025-05-21T07:18:00.195051Z","iopub.status.idle":"2025-05-21T07:18:00.200104Z","shell.execute_reply.started":"2025-05-21T07:18:00.195033Z","shell.execute_reply":"2025-05-21T07:18:00.199386Z"}},"outputs":[],"execution_count":null}]}